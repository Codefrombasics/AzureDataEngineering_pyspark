{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23390682-5902-47d2-94ec-1539511c637c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/04/13 13:54:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://157801e91612:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Basics Transformation</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa7878002b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark=SparkSession.builder.appName(\"Basics Transformation\").master(\"local[*]\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2cbe61d-188d-4a35-afba-2b11b262a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_data_1 = [\n",
    "    [\"001\",\"101\",\"John Doe\",\"30\",\"Male\",\"50000\",\"2015-01-01\"],\n",
    "    [\"002\",\"101\",\"Jane Smith\",\"25\",\"Female\",\"45000\",\"2016-02-15\"],\n",
    "    [\"003\",\"102\",\"Bob Brown\",\"35\",\"Male\",\"55000\",\"2014-05-01\"],\n",
    "    [\"004\",\"102\",\"Alice Lee\",\"28\",\"Female\",\"48000\",\"2017-09-30\"],\n",
    "    [\"005\",\"103\",\"Jack Chan\",\"40\",\"Male\",\"60000\",\"2013-04-01\"],\n",
    "    [\"006\",\"103\",\"Jill Wong\",\"32\",\"Female\",\"52000\",\"2018-07-01\"],\n",
    "    [\"007\",\"101\",\"James Johnson\",\"42\",\"Male\",\"70000\",\"2012-03-15\"],\n",
    "    [\"008\",\"102\",\"Kate Kim\",\"29\",\"Female\",\"51000\",\"2019-10-01\"],\n",
    "    [\"009\",\"103\",\"Tom Tan\",\"33\",\"\",\"58000\",\"2016-06-01\"],\n",
    "    [\"010\",\"104\",\"Lisa Lee\",\"27\",\"Female\",\"47000\",\"2018-08-01\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97ad2be1-a3a6-4560-b5b8-cd49a7a0f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_schema=\"employee_id string,department_id string,name string,age string,gender string,salary string,hire_date string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c579f523-d2d3-4aa3-ab4d-033ada2ee1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+\n",
      "|employee_id|department_id|         name|age|gender|salary| hire_date|\n",
      "+-----------+-------------+-------------+---+------+------+----------+\n",
      "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|\n",
      "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|\n",
      "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|\n",
      "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|\n",
      "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|\n",
      "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|\n",
      "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|\n",
      "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|\n",
      "|        009|          103|      Tom Tan| 33|      | 58000|2016-06-01|\n",
      "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|\n",
      "+-----------+-------------+-------------+---+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp=spark.createDataFrame(data=emp_data_1,schema=employee_schema)\n",
    "emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebf193e7-3bbb-41ff-95b0-cedffdf96636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#casting the column using col\n",
    "#casting salary into double\n",
    "from pyspark.sql.functions import col,cast\n",
    "\n",
    "emp_casted=emp.select(\"employee_id\",\"name\",\"age\",col(\"salary\").cast(\"double\"))\n",
    "emp_casted.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9497e9f1-5ea8-43fb-b8d4-0891e5ca1a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+\n",
      "|employee_id|         name|age| salary|    tax|\n",
      "+-----------+-------------+---+-------+-------+\n",
      "|        001|     John Doe| 30|50000.0|10000.0|\n",
      "|        002|   Jane Smith| 25|45000.0| 9000.0|\n",
      "|        003|    Bob Brown| 35|55000.0|11000.0|\n",
      "|        004|    Alice Lee| 28|48000.0| 9600.0|\n",
      "|        005|    Jack Chan| 40|60000.0|12000.0|\n",
      "|        006|    Jill Wong| 32|52000.0|10400.0|\n",
      "|        007|James Johnson| 42|70000.0|14000.0|\n",
      "|        008|     Kate Kim| 29|51000.0|10200.0|\n",
      "|        009|      Tom Tan| 33|58000.0|11600.0|\n",
      "|        010|     Lisa Lee| 27|47000.0| 9400.0|\n",
      "+-----------+-------------+---+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create a new column with title tax 20% of the salary\n",
    "# to create a new column or derived column we have to use withColumn\n",
    "\n",
    "emp_taxed=emp_casted.withColumn(\"tax\",col(\"salary\")*0.2)\n",
    "emp_taxed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6c0d55b-7c16-4e14-b59f-c657743373db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+------+------+\n",
      "|employee_id|         name|age| salary|    tax|dummy1|dummy2|\n",
      "+-----------+-------------+---+-------+-------+------+------+\n",
      "|        001|     John Doe| 30|50000.0|10000.0|     7|  Nine|\n",
      "|        002|   Jane Smith| 25|45000.0| 9000.0|     7|  Nine|\n",
      "|        003|    Bob Brown| 35|55000.0|11000.0|     7|  Nine|\n",
      "|        004|    Alice Lee| 28|48000.0| 9600.0|     7|  Nine|\n",
      "|        005|    Jack Chan| 40|60000.0|12000.0|     7|  Nine|\n",
      "|        006|    Jill Wong| 32|52000.0|10400.0|     7|  Nine|\n",
      "|        007|James Johnson| 42|70000.0|14000.0|     7|  Nine|\n",
      "|        008|     Kate Kim| 29|51000.0|10200.0|     7|  Nine|\n",
      "|        009|      Tom Tan| 33|58000.0|11600.0|     7|  Nine|\n",
      "|        010|     Lisa Lee| 27|47000.0| 9400.0|     7|  Nine|\n",
      "+-----------+-------------+---+-------+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#i want to create some dummy values- use lit()\n",
    "\n",
    "from pyspark.sql.functions import lit\n",
    "emp_taxed_new_columns=emp_taxed.withColumn(\"dummy1\",lit(7)).withColumn(\"dummy2\",lit(\"Nine\"))\n",
    "emp_taxed_new_columns.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31e25a06-995e-4253-b998-71a05399ca7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+---+-------+-------+------+------+\n",
      "|emp_id|         name|age| salary|    tax|dummy1|dummy2|\n",
      "+------+-------------+---+-------+-------+------+------+\n",
      "|   001|     John Doe| 30|50000.0|10000.0|     7|  Nine|\n",
      "|   002|   Jane Smith| 25|45000.0| 9000.0|     7|  Nine|\n",
      "|   003|    Bob Brown| 35|55000.0|11000.0|     7|  Nine|\n",
      "|   004|    Alice Lee| 28|48000.0| 9600.0|     7|  Nine|\n",
      "|   005|    Jack Chan| 40|60000.0|12000.0|     7|  Nine|\n",
      "|   006|    Jill Wong| 32|52000.0|10400.0|     7|  Nine|\n",
      "|   007|James Johnson| 42|70000.0|14000.0|     7|  Nine|\n",
      "|   008|     Kate Kim| 29|51000.0|10200.0|     7|  Nine|\n",
      "|   009|      Tom Tan| 33|58000.0|11600.0|     7|  Nine|\n",
      "|   010|     Lisa Lee| 27|47000.0| 9400.0|     7|  Nine|\n",
      "+------+-------------+---+-------+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renaming a column\n",
    "#select employee_id as emp_id, salary,age,tax \n",
    "\n",
    "emp_renamed=emp_taxed_new_columns.withColumnRenamed(\"employee_id\",\"emp_id\")\n",
    "emp_renamed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "811572d0-1b53-4f54-b967-88bf6d706d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+---+-------+-------+\n",
      "|emp_id|         name|age| salary|    tax|\n",
      "+------+-------------+---+-------+-------+\n",
      "|   001|     John Doe| 30|50000.0|10000.0|\n",
      "|   002|   Jane Smith| 25|45000.0| 9000.0|\n",
      "|   003|    Bob Brown| 35|55000.0|11000.0|\n",
      "|   004|    Alice Lee| 28|48000.0| 9600.0|\n",
      "|   005|    Jack Chan| 40|60000.0|12000.0|\n",
      "|   006|    Jill Wong| 32|52000.0|10400.0|\n",
      "|   007|James Johnson| 42|70000.0|14000.0|\n",
      "|   008|     Kate Kim| 29|51000.0|10200.0|\n",
      "|   009|      Tom Tan| 33|58000.0|11600.0|\n",
      "|   010|     Lisa Lee| 27|47000.0| 9400.0|\n",
      "+------+-------------+---+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropped_emp_rename=emp_renamed.drop(\"dummy1\",\"dummy2\").show\n",
    "dropped_emp_rename.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56ce6f3e-c815-433c-88c9-690a137892cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i want to print the employees who are paying more than 10000 as a their tax amount\n",
    "\n",
    "above_ten_thousand_tax=dropped_emp_rename.filter(\"tax>10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7f974a2-3594-4ded-b6c2-874dc8820dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:=======>                                                  (1 + 7) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+---+-------+-------+\n",
      "|emp_id|         name|age| salary|    tax|\n",
      "+------+-------------+---+-------+-------+\n",
      "|   007|James Johnson| 42|70000.0|14000.0|\n",
      "|   005|    Jack Chan| 40|60000.0|12000.0|\n",
      "|   009|      Tom Tan| 33|58000.0|11600.0|\n",
      "|   003|    Bob Brown| 35|55000.0|11000.0|\n",
      "|   006|    Jill Wong| 32|52000.0|10400.0|\n",
      "+------+-------------+---+-------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#i want to print 1st 5 highest tax payers from employees table\n",
    "top_5_taxpayers=above_ten_thousand_tax.orderBy(col(\"tax\").desc()).limit(5)\n",
    "top_5_taxpayers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "471dcbd1-2ce4-446b-a083-b6da7d25f6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what i want to create tax, dummy1 and dummy2 columns in one go\n",
    "\n",
    "#adding multiple columns \n",
    "\n",
    "columns={\"tax\": col(\"salary\")*0.2,\n",
    "         \"dummy1\":lit(7),\n",
    "         \"dummy2\":lit(\"Nine\")\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f7db202-b014-4405-8a55-87944a198496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---+-------+-------+------+------+\n",
      "|employee_id|         name|age| salary|    tax|dummy1|dummy2|\n",
      "+-----------+-------------+---+-------+-------+------+------+\n",
      "|        001|     John Doe| 30|50000.0|10000.0|     7|  Nine|\n",
      "|        002|   Jane Smith| 25|45000.0| 9000.0|     7|  Nine|\n",
      "|        003|    Bob Brown| 35|55000.0|11000.0|     7|  Nine|\n",
      "|        004|    Alice Lee| 28|48000.0| 9600.0|     7|  Nine|\n",
      "|        005|    Jack Chan| 40|60000.0|12000.0|     7|  Nine|\n",
      "|        006|    Jill Wong| 32|52000.0|10400.0|     7|  Nine|\n",
      "|        007|James Johnson| 42|70000.0|14000.0|     7|  Nine|\n",
      "|        008|     Kate Kim| 29|51000.0|10200.0|     7|  Nine|\n",
      "|        009|      Tom Tan| 33|58000.0|11600.0|     7|  Nine|\n",
      "|        010|     Lisa Lee| 27|47000.0| 9400.0|     7|  Nine|\n",
      "+-----------+-------------+---+-------+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_multi_column=emp_casted.withColumns(columns)\n",
    "emp_multi_column.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cd6a4f8-6572-4896-af2b-0afe68be1e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+\n",
      "|employee_id|department_id|         name|age|gender|salary| hire_date|\n",
      "+-----------+-------------+-------------+---+------+------+----------+\n",
      "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|\n",
      "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|\n",
      "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|\n",
      "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|\n",
      "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|\n",
      "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|\n",
      "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|\n",
      "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|\n",
      "|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|\n",
      "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|\n",
      "+-----------+-------------+-------------+---+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0da06553-c899-42bf-a66b-d5652a49fcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+----------+----------+\n",
      "|employee_id|department_id|         name|age|salary| hire_date|new_gender|\n",
      "+-----------+-------------+-------------+---+------+----------+----------+\n",
      "|        001|          101|     John Doe| 30| 50000|2015-01-01|         M|\n",
      "|        002|          101|   Jane Smith| 25| 45000|2016-02-15|         F|\n",
      "|        003|          102|    Bob Brown| 35| 55000|2014-05-01|         M|\n",
      "|        004|          102|    Alice Lee| 28| 48000|2017-09-30|         F|\n",
      "|        005|          103|    Jack Chan| 40| 60000|2013-04-01|         M|\n",
      "|        006|          103|    Jill Wong| 32| 52000|2018-07-01|         F|\n",
      "|        007|          101|James Johnson| 42| 70000|2012-03-15|         M|\n",
      "|        008|          102|     Kate Kim| 29| 51000|2019-10-01|         F|\n",
      "|        009|          103|      Tom Tan| 33| 58000|2016-06-01|      null|\n",
      "|        010|          104|     Lisa Lee| 27| 47000|2018-08-01|         F|\n",
      "+-----------+-------------+-------------+---+------+----------+----------+\n",
      "\n",
      "+-----------+-------------+-------------+---+------+----------+----------+\n",
      "|employee_id|department_id|         name|age|salary| hire_date|new_gender|\n",
      "+-----------+-------------+-------------+---+------+----------+----------+\n",
      "|        001|          101|     John Doe| 30| 50000|2015-01-01|         M|\n",
      "|        002|          101|   Jane Smith| 25| 45000|2016-02-15|         F|\n",
      "|        003|          102|    Bob Brown| 35| 55000|2014-05-01|         M|\n",
      "|        004|          102|    Alice Lee| 28| 48000|2017-09-30|         F|\n",
      "|        005|          103|    Jack Chan| 40| 60000|2013-04-01|         M|\n",
      "|        006|          103|    Jill Wong| 32| 52000|2018-07-01|         F|\n",
      "|        007|          101|James Johnson| 42| 70000|2012-03-15|         M|\n",
      "|        008|          102|     Kate Kim| 29| 51000|2019-10-01|         F|\n",
      "|        009|          103|      Tom Tan| 33| 58000|2016-06-01|      null|\n",
      "|        010|          104|     Lisa Lee| 27| 47000|2018-08-01|         F|\n",
      "+-----------+-------------+-------------+---+------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# change Male to M and Female to F name the columns as new_gender\n",
    "\n",
    "# we have to use 'when'(like case in sql)\n",
    "\n",
    "from pyspark.sql.functions import when,expr\n",
    "\n",
    "emp_gender=emp.withColumn(\"new_gender\",when(col(\"gender\")==\"Male\",\"M\").when(col(\"gender\")==\"Female\",\"F\").otherwise(None)).drop(\"gender\")\n",
    "emp_gender.show()\n",
    "\n",
    "\n",
    "emp_gender_sql=emp.withColumn(\"new_gender\",expr(\"case when gender='Male' then 'M' when gender='Female' then 'F' else null end\")).drop(\"gender\")\n",
    "emp_gender_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b6e5726-f460-4ef9-a077-b15763114695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+----------+----------+\n",
      "|employee_id|department_id|         name|age|salary| hire_date|new_gender|\n",
      "+-----------+-------------+-------------+---+------+----------+----------+\n",
      "|        001|          101|     John Doe| 30| 50000|2015-01-01|         M|\n",
      "|        002|          101|   Jane Smith| 25| 45000|2016-02-15|         F|\n",
      "|        003|          102|    Bob Brown| 35| 55000|2014-05-01|         M|\n",
      "|        004|          102|    Alice Lee| 28| 48000|2017-09-30|         F|\n",
      "|        005|          103|    Jack Chan| 40| 60000|2013-04-01|         M|\n",
      "|        006|          103|    Jill Wong| 32| 52000|2018-07-01|         F|\n",
      "|        007|          101|James Johnson| 42| 70000|2012-03-15|         M|\n",
      "|        008|          102|     Kate Kim| 29| 51000|2019-10-01|         F|\n",
      "|        009|          103|      Tom Tan| 33| 58000|2016-06-01|      null|\n",
      "|        010|          104|     Lisa Lee| 27| 47000|2018-08-01|         F|\n",
      "+-----------+-------------+-------------+---+------+----------+----------+\n",
      "\n",
      "root\n",
      " |-- employee_id: string (nullable = true)\n",
      " |-- department_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- hire_date: date (nullable = true)\n",
      " |-- new_gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert a date\n",
    "# select *, to_date(hire_date,\"yyyy-mm-dd\") as hire_date\n",
    "\n",
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "emp_date_converted=emp_gender_sql.withColumn(\"hire_date\",to_date(col(\"hire_date\"),'yyyy-MM-dd'))\n",
    "emp_date_converted.show()\n",
    "emp_date_converted.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01a72132-9964-43d0-8fc4-5a74245b7ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+----------+----------+----------+--------------------------+\n",
      "|employee_id|department_id|name         |age|salary|hire_date |new_gender|date_now  |timestamp                 |\n",
      "+-----------+-------------+-------------+---+------+----------+----------+----------+--------------------------+\n",
      "|001        |101          |John Doe     |30 |50000 |2015-01-01|M         |2025-04-13|2025-04-13 15:03:16.762802|\n",
      "|002        |101          |Jane Smith   |25 |45000 |2016-02-15|F         |2025-04-13|2025-04-13 15:03:16.762802|\n",
      "|003        |102          |Bob Brown    |35 |55000 |2014-05-01|M         |2025-04-13|2025-04-13 15:03:16.762802|\n",
      "|004        |102          |Alice Lee    |28 |48000 |2017-09-30|F         |2025-04-13|2025-04-13 15:03:16.762802|\n",
      "|005        |103          |Jack Chan    |40 |60000 |2013-04-01|M         |2025-04-13|2025-04-13 15:03:16.762802|\n",
      "|006        |103          |Jill Wong    |32 |52000 |2018-07-01|F         |2025-04-13|2025-04-13 15:03:16.762802|\n",
      "|007        |101          |James Johnson|42 |70000 |2012-03-15|M         |2025-04-13|2025-04-13 15:03:16.762802|\n",
      "|008        |102          |Kate Kim     |29 |51000 |2019-10-01|F         |2025-04-13|2025-04-13 15:03:16.762802|\n",
      "|009        |103          |Tom Tan      |33 |58000 |2016-06-01|null      |2025-04-13|2025-04-13 15:03:16.762802|\n",
      "|010        |104          |Lisa Lee     |27 |47000 |2018-08-01|F         |2025-04-13|2025-04-13 15:03:16.762802|\n",
      "+-----------+-------------+-------------+---+------+----------+----------+----------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# i want to create a dataframe with current date and timestamp\n",
    "from pyspark.sql.functions import current_date,current_timestamp\n",
    "emp_dated=emp_date_converted.withColumn(\"date_now\",current_date()).withColumn(\"timestamp\",current_timestamp())\n",
    "emp_dated.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "03a04d83-0355-490c-81ea-15eb944ebf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+----------+----------+----------+--------------------+\n",
      "|employee_id|department_id|         name|age|salary| hire_date|new_gender|  date_now|           timestamp|\n",
      "+-----------+-------------+-------------+---+------+----------+----------+----------+--------------------+\n",
      "|        001|          101|     John Doe| 30| 50000|2015-01-01|         M|2025-04-13|2025-04-13 15:04:...|\n",
      "|        002|          101|   Jane Smith| 25| 45000|2016-02-15|         F|2025-04-13|2025-04-13 15:04:...|\n",
      "|        003|          102|    Bob Brown| 35| 55000|2014-05-01|         M|2025-04-13|2025-04-13 15:04:...|\n",
      "|        004|          102|    Alice Lee| 28| 48000|2017-09-30|         F|2025-04-13|2025-04-13 15:04:...|\n",
      "|        005|          103|    Jack Chan| 40| 60000|2013-04-01|         M|2025-04-13|2025-04-13 15:04:...|\n",
      "|        006|          103|    Jill Wong| 32| 52000|2018-07-01|         F|2025-04-13|2025-04-13 15:04:...|\n",
      "|        007|          101|James Johnson| 42| 70000|2012-03-15|         M|2025-04-13|2025-04-13 15:04:...|\n",
      "|        008|          102|     Kate Kim| 29| 51000|2019-10-01|         F|2025-04-13|2025-04-13 15:04:...|\n",
      "|        010|          104|     Lisa Lee| 27| 47000|2018-08-01|         F|2025-04-13|2025-04-13 15:04:...|\n",
      "+-----------+-------------+-------------+---+------+----------+----------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dropping the null records\n",
    "emp_2=emp_dated.dropna()\n",
    "emp_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "25f57740-834e-4f73-97bb-4a4ba1b7048d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: string (nullable = true)\n",
      " |-- department_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- hire_date: date (nullable = true)\n",
      " |-- date_now: date (nullable = false)\n",
      " |-- timestamp: timestamp (nullable = false)\n",
      " |-- gender: string (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how to handle null values\n",
    "#select *, nvl(\"new_gender\",0) as new_gender from employees\n",
    "\n",
    "from pyspark.sql.functions import coalesce,lit\n",
    "emp_fill_null=emp_dated.withColumn(\"gender\",coalesce(col(\"new_gender\"),lit(0))).drop(\"new_gender\")\n",
    "emp_fill_null.printSchema()\n",
    "emp_fill_null.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6047f9a-effd-4195-b762-ad6585ce172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#writing the final result as csv file\n",
    "emp_fill_null.write.format(\"csv\").save(\"data/output/13/emp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87ca12b7-34cc-4234-ac41-dad07b20596c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 128:==============>                                          (2 + 6) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|department_id|\n",
      "+-------------+\n",
      "|          101|\n",
      "|          102|\n",
      "|          103|\n",
      "|          104|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "emp.select(emp.department_id).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "648a088a-4d94-427c-a23e-ac78d5516b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 131:>                                                        (0 + 8) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+\n",
      "|employee_id|department_id|         name|age|gender|salary| hire_date|\n",
      "+-----------+-------------+-------------+---+------+------+----------+\n",
      "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|\n",
      "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|\n",
      "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|\n",
      "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|\n",
      "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|\n",
      "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|\n",
      "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|\n",
      "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|\n",
      "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|\n",
      "|        009|          103|      Tom Tan| 33|      | 58000|2016-06-01|\n",
      "+-----------+-------------+-------------+---+------+------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "emp.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede1322f-a584-40aa-aa36-93da22db4cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
