{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "055b2d0e-ac6d-49a8-a4b3-c5238ec4b8e9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://157801e91612:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Streaming from Kafka</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f2285da1000>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession \n",
    "    .builder \n",
    "    .appName(\"Streaming from Kafka\") \n",
    "    .config(\"spark.streaming.stopGracefullyOnShutdown\", True) \n",
    "    .config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0')\n",
    "    .config(\"spark.sql.shuffle.partitions\", 4)\n",
    "    .master(\"local[*]\") \n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e934add7-f69f-46e9-8dd6-5915842a44ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the kafka_df to read from kafka\n",
    "\n",
    "kafka_df = (\n",
    "    spark\n",
    "    .readStream\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\")\n",
    "    .option(\"subscribe\", \"people\") #people is the topic name\n",
    "    .option(\"startingOffsets\", \"earliest\")\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3043cb9c-b820-4c8e-a063-272669cfb5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kafka_df.printSchema()\n",
    "# kafka_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21c89d3f-dce0-4f47-a686-d1f38eebc27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "kafka_json_df = kafka_df.withColumn(\"value\", expr(\"cast(value as string)\"))\n",
    "# kafka_json_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0efc922f-f833-44d1-b079-bb3236651105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, StructField, StructType, ArrayType, LongType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "915ab8b6-b872-461d-972f-282f47c679df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=spark.read.json(\"data/input/people1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6536817a-1c4c-4c41-a9af-15c49a27c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myschema=df.schema\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, ArrayType\n",
    "myschema=StructType([\n",
    "    StructField(\"id\", LongType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", LongType(), True),\n",
    "    StructField(\"contacts\", StructType([\n",
    "        StructField(\"email\", StringType(), True),\n",
    "        StructField(\"phones\", ArrayType(StringType()), True)\n",
    "    ]), True),\n",
    "    StructField(\"skills\", ArrayType(StringType()), True),\n",
    "    StructField(\"projects\", ArrayType(StructType([\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"duration\", StringType(), True)\n",
    "    ])), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7803631-2953-464c-891a-4f8d453083aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json,col\n",
    "\n",
    "streaming_df = kafka_json_df.withColumn(\"values_json\", from_json(col(\"value\"), myschema)).selectExpr(\"values_json.*\")\n",
    "# streaming_df.show(truncate=False)\n",
    "# kafka_json_df.select(\"value\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3999ade5-4117-4f93-a2d7-632ed1ed6b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- contacts: struct (nullable = true)\n",
      " |    |-- email: string (nullable = true)\n",
      " |    |-- phones: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- skills: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- projects: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- duration: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "streaming_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c7ee6ea-133c-4eab-8df6-935de30a122f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- phone: string (nullable = true)\n",
      " |-- skill: string (nullable = true)\n",
      " |-- project_name: string (nullable = true)\n",
      " |-- project_duration: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "df_flat = streaming_df\\\n",
    "    .withColumn(\"email\", col(\"contacts\").getField(\"email\")) \\\n",
    "    .withColumn(\"phones\", col(\"contacts\").getField(\"phones\")) \\\n",
    "    .withColumn(\"phone\", explode(\"phones\")) \\\n",
    "    .withColumn(\"skill\", explode(\"skills\")) \\\n",
    "    .withColumn(\"project\", explode(\"projects\")) \\\n",
    "    .withColumn(\"project_name\", col(\"project.name\")) \\\n",
    "    .withColumn(\"project_duration\", col(\"project.duration\")) \\\n",
    "    .drop(\"contacts\", \"skills\", \"projects\", \"phones\", \"project\")\n",
    "\n",
    "df_flat.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63619113-b733-4c26-9871-22d1cf12d5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/04/19 06:56:16 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+---+----+---+---------------+------------+-----+------------+----------------+\n",
      "| id|name|age|          email|       phone|skill|project_name|project_duration|\n",
      "+---+----+---+---------------+------------+-----+------------+----------------+\n",
      "|  2| Bob| 25|bob@example.com|555-111-2222| Java|       Gamma|        4 months|\n",
      "|  2| Bob| 25|bob@example.com|555-111-2222|Kafka|       Gamma|        4 months|\n",
      "+---+----+---+---------------+------------+-----+------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+---+-------+---+-------------------+------------+-------+------------+----------------+\n",
      "| id|   name|age|              email|       phone|  skill|project_name|project_duration|\n",
      "+---+-------+---+-------------------+------------+-------+------------+----------------+\n",
      "|  3|Charlie| 35|charlie@example.com|444-333-2222|  Scala|       Delta|        2 months|\n",
      "|  3|Charlie| 35|charlie@example.com|444-333-2222|  Scala|     Epsilon|        5 months|\n",
      "|  3|Charlie| 35|charlie@example.com|444-333-2222|Airflow|       Delta|        2 months|\n",
      "|  3|Charlie| 35|charlie@example.com|444-333-2222|Airflow|     Epsilon|        5 months|\n",
      "|  3|Charlie| 35|charlie@example.com|222-333-4444|  Scala|       Delta|        2 months|\n",
      "|  3|Charlie| 35|charlie@example.com|222-333-4444|  Scala|     Epsilon|        5 months|\n",
      "|  3|Charlie| 35|charlie@example.com|222-333-4444|Airflow|       Delta|        2 months|\n",
      "|  3|Charlie| 35|charlie@example.com|222-333-4444|Airflow|     Epsilon|        5 months|\n",
      "+---+-------+---+-------------------+------------+-------+------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_flat\n",
    " .writeStream\n",
    " .format(\"console\")\n",
    " .outputMode(\"append\")\n",
    " .trigger(once=True)\n",
    " .option(\"checkpointLocation\", \"checkpoint_dir_kafka\")\n",
    " .start()\n",
    " .awaitTermination())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec06ce56-6843-4fd0-ba91-c1a94c5e3b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
