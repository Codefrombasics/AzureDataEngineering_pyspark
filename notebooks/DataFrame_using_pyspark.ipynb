{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "233880a4-0c62-4870-a436-a91fae377b0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show\n"
     ]
    }
   ],
   "source": [
    "print(\"show\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05b3a63c-8263-4104-a306-525a88cbac59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Creating Dataframe using Row()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75fd7ee5-ebeb-41af-b9d1-c3489333db6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x=[('Manish',23),(\"John\",24),(\"Kiruba\",31)]\n",
    "rdd=sc.parallelize(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "423c0f72-8213-49fa-9378-03b5bd72a359",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0404d25-ab56-4278-915b-fdf6cc13b1e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[5]: pyspark.sql.types.Row"
     ]
    }
   ],
   "source": [
    "customer=Row(\"Name\",\"Age\")\n",
    "type(customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acb866f8-ea01-4b6e-89ef-89fbf7a97dab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[11]: [Row(Name='Manish', Age=23),\n Row(Name='John', Age=24),\n Row(Name='Kiruba', Age=31)]"
     ]
    }
   ],
   "source": [
    "customerrow=rdd.map(lambda x:customer(*x))\n",
    "customerrow.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7e661e2-501e-4466-955d-ea62369d52a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n|  Name|Age|\n+------+---+\n|Manish| 23|\n|  John| 24|\n|Kiruba| 31|\n+------+---+\n\n"
     ]
    }
   ],
   "source": [
    "dataframe=spark.createDataFrame(customerrow)\n",
    "dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea310120-7b10-4922-813c-6807a1b533ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Name: string (nullable = true)\n |-- Age: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df2=spark.createDataFrame(rdd,[\"Name\",\"Age\"])\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fca328ef-2d64-4c2d-8f50-81e2768c1943",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## defining a schema using StructType()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ea3584c-d5b7-401b-9a99-73daaac195c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Name: string (nullable = true)\n |-- Age: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema=StructType([StructField(\"Name\",StringType()), StructField(\"Age\",IntegerType())])\n",
    "df2=spark.createDataFrame(rdd,schema)\n",
    "df2.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3807134-21b7-4df2-af59-71c536230a51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## using String type for schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a935df96-75f5-47b9-ad60-f5ec51f1d0d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Name: string (nullable = true)\n |-- Age: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df2=spark.createDataFrame(rdd,\"Name:string, Age:int\")\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c34a0987-b65a-4e7f-8d32-2b1f79230e1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+------+------+\n|eid|    ename|  sal|gender|deptno|\n+---+---------+-----+------+------+\n|101|Hariharan|10000|     m|    11|\n|102|    Kalai|20000|     f|    12|\n|103|    Sivam|30000|     m|    11|\n|104|    Blake|35000|     m|    12|\n|105|    James|40000|     m|    11|\n+---+---------+-----+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "data=[(101,'Hariharan',10000,'m',11),\n",
    "(102,'Kalai',20000,'f',12),\n",
    "(103,'Sivam',30000,'m',11),\n",
    "(104,'Blake',35000,'m',12),\n",
    "(105,'James',40000,'m',11)]\n",
    "\n",
    "rdd=sc.parallelize(data)\n",
    "df=spark.createDataFrame(rdd,['eid','ename','sal','gender','deptno'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7545598-27ff-4567-8216-d010881997b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- eid: long (nullable = true)\n |-- ename: string (nullable = true)\n |-- sal: long (nullable = true)\n |-- gender: string (nullable = true)\n |-- deptno: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08604792-b9cd-4fe3-8f58-d8155e4eca31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[24]: [Row(eid=101, ename='Hariharan', sal=10000, gender='m', deptno=11),\n Row(eid=102, ename='Kalai', sal=20000, gender='f', deptno=12),\n Row(eid=103, ename='Sivam', sal=30000, gender='m', deptno=11),\n Row(eid=104, ename='Blake', sal=35000, gender='m', deptno=12),\n Row(eid=105, ename='James', sal=40000, gender='m', deptno=11)]"
     ]
    }
   ],
   "source": [
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19c6fad3-f110-4c66-b934-de6b36aa5568",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[25]: ['101,Hariharan,10000,m,11',\n '102,Kalai,20000,f,12',\n '103,Sivam,30000,m,11',\n '104,Blake,35000,m,12',\n '105,James,40000,m,11']"
     ]
    }
   ],
   "source": [
    "rdd=sc.textFile(\"dbfs:/FileStore/sample.txt\")\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbe95343-8bf9-405b-a6e5-6d924fb9aec4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[27]: 2"
     ]
    }
   ],
   "source": [
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3700b3b-dd10-449b-83c4-d021ebc34211",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[28]: [['101', 'Hariharan', '10000', 'm', '11'],\n ['102', 'Kalai', '20000', 'f', '12'],\n ['103', 'Sivam', '30000', 'm', '11'],\n ['104', 'Blake', '35000', 'm', '12'],\n ['105', 'James', '40000', 'm', '11']]"
     ]
    }
   ],
   "source": [
    "rdd2=rdd.map(lambda x:x.split(','))\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e65f2fd-a894-4cca-9d3b-2df12a33ffcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[29]: [Row(eid=101, ename='Hariharan', esal=10000, gender='m', deptno=11),\n Row(eid=102, ename='Kalai', esal=20000, gender='f', deptno=12),\n Row(eid=103, ename='Sivam', esal=30000, gender='m', deptno=11),\n Row(eid=104, ename='Blake', esal=35000, gender='m', deptno=12),\n Row(eid=105, ename='James', esal=40000, gender='m', deptno=11)]"
     ]
    }
   ],
   "source": [
    "#convert every list into Row\n",
    "rdd3=rdd2.map(lambda x:Row(eid=int(x[0]),ename=x[1],esal=int(x[2]),gender=x[3],deptno=int(x[4])))\n",
    "rdd3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a72791b3-8116-4c8c-801c-b5c9d4d632b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- eid: long (nullable = true)\n |-- ename: string (nullable = true)\n |-- esal: long (nullable = true)\n |-- gender: string (nullable = true)\n |-- deptno: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df=spark.createDataFrame(rdd3)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "357b994f-213c-4887-8926-d404f66c74f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+------+------+\n|eid|    ename| esal|gender|deptno|\n+---+---------+-----+------+------+\n|101|Hariharan|10000|     m|    11|\n|102|    Kalai|20000|     f|    12|\n|103|    Sivam|30000|     m|    11|\n|104|    Blake|35000|     m|    12|\n|105|    James|40000|     m|    11|\n+---+---------+-----+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6566ee55-e725-4738-b65e-587e82585cb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## DataFrame API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86a95add-c0aa-4434-acc8-02f8d7bcd23b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####  select-> to select or extract a particular column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e3a09e2-cc6e-4377-a23b-ea2026195cc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n|    ename| esal|\n+---------+-----+\n|Hariharan|10000|\n|    Kalai|20000|\n|    Sivam|30000|\n|    Blake|35000|\n|    James|40000|\n+---------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "smallddf=df.select(\"ename\",\"esal\")\n",
    "smallddf.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cc9c90c-b181-4aae-b00d-db52c6ccac85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Transformation on DataFrame will return DataFrame\n",
    "\n",
    "df and smallddf are dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56415c66-1e54-49a1-9a9c-e32dcf30403f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n| esal|    ename|\n+-----+---------+\n|10000|Hariharan|\n|20000|    Kalai|\n|30000|    Sivam|\n|35000|    Blake|\n|40000|    James|\n+-----+---------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select(df.esal,df.ename).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6ce68e7-bc35-44d3-90b9-2424a650d975",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-------------+\n|    ename| esal|(esal + 3000)|\n+---------+-----+-------------+\n|Hariharan|10000|        13000|\n|    Kalai|20000|        23000|\n|    Sivam|30000|        33000|\n|    Blake|35000|        38000|\n|    James|40000|        43000|\n+---------+-----+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "#select ename,esal,esal+3000 from employee\n",
    "\n",
    "bonusdf=df.select(df.ename,df.esal,df.esal+3000)\n",
    "bonusdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02eaf666-cec7-4814-a4fd-c2d8c7292fa2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----+\n|    ename| esal|bonus|\n+---------+-----+-----+\n|Hariharan|10000|13000|\n|    Kalai|20000|23000|\n|    Sivam|30000|33000|\n|    Blake|35000|38000|\n|    James|40000|43000|\n+---------+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# bonusdf=df.select(\"ename\",\"esal\",\"esal+3000\") #error\n",
    "bonusdf=df.selectExpr(\"ename\",\"esal\",\"esal+3000 bonus\")\n",
    "bonusdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9fcb8f3d-04ce-4131-aeb3-b045d06ba0e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### filter() to get the rows based on the condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60e582a4-b924-4caa-9b81-afb728ae1f19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+------+------+\n|eid|    ename| esal|gender|deptno|\n+---+---------+-----+------+------+\n|101|Hariharan|10000|     m|    11|\n|102|    Kalai|20000|     f|    12|\n|103|    Sivam|30000|     m|    11|\n|104|    Blake|35000|     m|    12|\n|105|    James|40000|     m|    11|\n+---+---------+-----+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "#select * from employees where salary>3000\n",
    "df3=df.filter(df.esal>3000)\n",
    "df3.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0367101b-27be-490c-9464-12f526f16ab9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n|ename| esal|\n+-----+-----+\n|Blake|35000|\n|James|40000|\n+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df4=df.filter(df.esal>30000).select(\"ename\",\"esal\")\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09c98191-dd21-472b-b9c9-07aa55c14147",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n|    ename| esal|\n+---------+-----+\n|Hariharan|10000|\n|    Kalai|20000|\n|    Sivam|30000|\n|    Blake|35000|\n|    James|40000|\n+---------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df4=df.select(\"ename\",\"esal\").filter(df.esal>30000)\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "041b2228-5b5e-4fbe-b15f-70732ef88383",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n|    ename| esal|\n+---------+-----+\n|Hariharan|10000|\n|    Sivam|30000|\n|    James|40000|\n+---------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df5=df.filter(df.deptno==11).select(\"ename\",\"esal\")\n",
    "df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b214b263-0ade-4794-bbd1-f67a10a4f08f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[51]: 3"
     ]
    }
   ],
   "source": [
    "df5.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3c16286-fad4-4cbc-8c01-7b29a3e48d0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[52]: [Row(ename='Hariharan', esal=10000),\n Row(ename='Sivam', esal=30000),\n Row(ename='James', esal=40000)]"
     ]
    }
   ],
   "source": [
    "df5.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62f92d5f-9ac0-47f1-8d0d-5e86831456bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[53]: ['eid', 'ename', 'esal', 'gender', 'deptno']"
     ]
    }
   ],
   "source": [
    "df.columns#return the column list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5acbd6d9-71d2-4e60-ae11-e19db9378492",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----+------------------+------+------------------+\n|summary|               eid|ename|              esal|gender|            deptno|\n+-------+------------------+-----+------------------+------+------------------+\n|  count|                 5|    5|                 5|     5|                 5|\n|   mean|             103.0| null|           27000.0|  null|              11.4|\n| stddev|1.5811388300841898| null|12041.594578792296|  null|0.5477225575051661|\n|    min|               101|Blake|             10000|     f|                11|\n|    max|               105|Sivam|             40000|     m|                12|\n+-------+------------------+-----+------------------+------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f6e54a6-5dac-4749-b4a2-e953444bc115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df6=df.select(df.deptno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7c1fc6e-0bbc-477b-afe3-313695d3d8f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### distinct to filter the duplicate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1906858e-4e3b-414a-abf5-e9058702fde7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n|deptno|\n+------+\n|    12|\n|    11|\n+------+\n\n"
     ]
    }
   ],
   "source": [
    "df6.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63afa00f-39cb-4a30-9e03-bd85a75ac7e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n|deptno|\n+------+\n|    12|\n|    11|\n+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select(\"deptno\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef4a2cfd-2080-4bd1-a895-a272cda29bb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### orderBy() to order the data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15d499b2-324b-4477-823a-a2bb2f531e70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+------+------+\n|eid|    ename| esal|gender|deptno|\n+---+---------+-----+------+------+\n|105|    James|40000|     m|    11|\n|101|Hariharan|10000|     m|    11|\n|103|    Sivam|30000|     m|    11|\n|104|    Blake|35000|     m|    12|\n|102|    Kalai|20000|     f|    12|\n+---+---------+-----+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\"deptno\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b36ded0-293c-4522-a2a6-65720cde0beb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+------+------+\n|eid|    ename| esal|gender|deptno|\n+---+---------+-----+------+------+\n|104|    Blake|35000|     m|    12|\n|101|Hariharan|10000|     m|    11|\n|105|    James|40000|     m|    11|\n|102|    Kalai|20000|     f|    12|\n|103|    Sivam|30000|     m|    11|\n+---+---------+-----+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\"ename\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fb2b6eb-36c9-4b02-a1c8-ff4401b8a669",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+------+------+\n|eid|    ename| esal|gender|deptno|\n+---+---------+-----+------+------+\n|101|Hariharan|10000|     m|    11|\n|103|    Sivam|30000|     m|    11|\n|105|    James|40000|     m|    11|\n|102|    Kalai|20000|     f|    12|\n|104|    Blake|35000|     m|    12|\n+---+---------+-----+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.distinct().orderBy(\"deptno\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4aa2910-f772-4ff0-a315-b1b6ececc0b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Sort() to arrange in ascending and desending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7ab4179-2a9e-408e-81d2-196256b54c3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+------+------+\n|eid|    ename| esal|gender|deptno|\n+---+---------+-----+------+------+\n|101|Hariharan|10000|     m|    11|\n|102|    Kalai|20000|     f|    12|\n|103|    Sivam|30000|     m|    11|\n|104|    Blake|35000|     m|    12|\n|105|    James|40000|     m|    11|\n+---+---------+-----+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.sort(df.esal).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10a58a65-e80a-44c5-b73d-c54df5564566",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+------+------+\n|eid|    ename| esal|gender|deptno|\n+---+---------+-----+------+------+\n|105|    James|40000|     m|    11|\n|104|    Blake|35000|     m|    12|\n|103|    Sivam|30000|     m|    11|\n|102|    Kalai|20000|     f|    12|\n|101|Hariharan|10000|     m|    11|\n+---+---------+-----+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.sort(df.esal.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3882420-b427-485b-9834-67e3a6a9c9be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+------+------+\n|eid|    ename| esal|gender|deptno|\n+---+---------+-----+------+------+\n|101|Hariharan|10000|     m|    11|\n|102|    Kalai|20000|     f|    12|\n|103|    Sivam|30000|     m|    11|\n|104|    Blake|35000|     m|    12|\n|105|    James|40000|     m|    11|\n+---+---------+-----+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab7ebc41-c2ac-4e5a-b6e6-b4486e0edbab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "drop() to delete a particular column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "628e51e0-227f-4054-874f-5ea4e9f0026f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+------+\n|eid|    ename| esal|deptno|\n+---+---------+-----+------+\n|101|Hariharan|10000|    11|\n|102|    Kalai|20000|    12|\n|103|    Sivam|30000|    11|\n|104|    Blake|35000|    12|\n|105|    James|40000|    11|\n+---+---------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "df7=df.drop(\"gender\")\n",
    "df7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25dd870f-427b-4856-8cec-736bccde3618",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+\n|eid|    ename| esal|\n+---+---------+-----+\n|101|Hariharan|10000|\n|102|    Kalai|20000|\n|103|    Sivam|30000|\n|104|    Blake|35000|\n|105|    James|40000|\n+---+---------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df8=df.drop(\"deptno\",\"gender\")\n",
    "df8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82695ee8-e489-4017-9e05-8af3830ba44c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n| _1|  _2| _3|\n+---+----+---+\n| 11|2000|  m|\n| 11|2000|  m|\n| 11|2500|  f|\n+---+----+---+\n\n"
     ]
    }
   ],
   "source": [
    "data=[(11,2000,'m'),(11,2000,'m'),(11,2500,'f')]\n",
    "dfnew=spark.createDataFrame(data)\n",
    "dfnew.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15878af8-3f0d-482a-a069-cced9f7b9caa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-4204435062209565>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m dfnew\u001B[38;5;241m.\u001B[39mdropDuplicates([\u001B[43m_1\u001B[49m,_2])\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name '_1' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-4204435062209565>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m dfnew\u001B[38;5;241m.\u001B[39mdropDuplicates([\u001B[43m_1\u001B[49m,_2])\u001B[38;5;241m.\u001B[39mshow()\n\n\u001B[0;31mNameError\u001B[0m: name '_1' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name '_1' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfnew.dropDuplicates([_1,_2]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "350e2b71-2713-44ed-9f9c-cd7a4be59b17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-4204435062209566>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mdfnew\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropDuplicates\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdfnew\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_1\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdfnew\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_2\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:3916\u001B[0m, in \u001B[0;36mDataFrame.dropDuplicates\u001B[0;34m(self, subset)\u001B[0m\n",
       "\u001B[1;32m   3914\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mdropDuplicates()\n",
       "\u001B[1;32m   3915\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m-> 3916\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mdropDuplicates(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jseq\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubset\u001B[49m\u001B[43m)\u001B[49m)\n",
       "\u001B[1;32m   3917\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2624\u001B[0m, in \u001B[0;36mDataFrame._jseq\u001B[0;34m(self, cols, converter)\u001B[0m\n",
       "\u001B[1;32m   2618\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_jseq\u001B[39m(\n",
       "\u001B[1;32m   2619\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n",
       "\u001B[1;32m   2620\u001B[0m     cols: Sequence,\n",
       "\u001B[1;32m   2621\u001B[0m     converter: Optional[Callable[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrimitiveType\u001B[39m\u001B[38;5;124m\"\u001B[39m, JavaObject]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n",
       "\u001B[1;32m   2622\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m JavaObject:\n",
       "\u001B[1;32m   2623\u001B[0m     \u001B[38;5;124;03m\"\"\"Return a JVM Seq of Columns from a list of Column or names\"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 2624\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_to_seq\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcols\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconverter\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/column.py:89\u001B[0m, in \u001B[0;36m_to_seq\u001B[0;34m(sc, cols, converter)\u001B[0m\n",
       "\u001B[1;32m     87\u001B[0m     cols \u001B[38;5;241m=\u001B[39m [converter(c) \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m cols]\n",
       "\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m sc\u001B[38;5;241m.\u001B[39m_jvm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[0;32m---> 89\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jvm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPythonUtils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtoSeq\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1313\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n",
       "\u001B[0;32m-> 1313\u001B[0m     args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_args\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1315\u001B[0m     command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m         args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m         proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m     answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1277\u001B[0m, in \u001B[0;36mJavaMember._build_args\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_args\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n",
       "\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\u001B[0;32m-> 1277\u001B[0m         (new_args, temp_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1278\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m   1279\u001B[0m         new_args \u001B[38;5;241m=\u001B[39m args\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1264\u001B[0m, in \u001B[0;36mJavaMember._get_args\u001B[0;34m(self, args)\u001B[0m\n",
       "\u001B[1;32m   1262\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m converter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39mconverters:\n",
       "\u001B[1;32m   1263\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter\u001B[38;5;241m.\u001B[39mcan_convert(arg):\n",
       "\u001B[0;32m-> 1264\u001B[0m         temp_arg \u001B[38;5;241m=\u001B[39m \u001B[43mconverter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1265\u001B[0m         temp_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n",
       "\u001B[1;32m   1266\u001B[0m         new_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_collections.py:511\u001B[0m, in \u001B[0;36mListConverter.convert\u001B[0;34m(self, object, gateway_client)\u001B[0m\n",
       "\u001B[1;32m    509\u001B[0m java_list \u001B[38;5;241m=\u001B[39m ArrayList()\n",
       "\u001B[1;32m    510\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m element \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mobject\u001B[39m:\n",
       "\u001B[0;32m--> 511\u001B[0m     \u001B[43mjava_list\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43melement\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m java_list\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1313\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n",
       "\u001B[0;32m-> 1313\u001B[0m     args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_args\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1315\u001B[0m     command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m         args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m         proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m     answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1277\u001B[0m, in \u001B[0;36mJavaMember._build_args\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_args\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n",
       "\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\u001B[0;32m-> 1277\u001B[0m         (new_args, temp_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1278\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m   1279\u001B[0m         new_args \u001B[38;5;241m=\u001B[39m args\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1264\u001B[0m, in \u001B[0;36mJavaMember._get_args\u001B[0;34m(self, args)\u001B[0m\n",
       "\u001B[1;32m   1262\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m converter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39mconverters:\n",
       "\u001B[1;32m   1263\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter\u001B[38;5;241m.\u001B[39mcan_convert(arg):\n",
       "\u001B[0;32m-> 1264\u001B[0m         temp_arg \u001B[38;5;241m=\u001B[39m \u001B[43mconverter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1265\u001B[0m         temp_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n",
       "\u001B[1;32m   1266\u001B[0m         new_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_collections.py:510\u001B[0m, in \u001B[0;36mListConverter.convert\u001B[0;34m(self, object, gateway_client)\u001B[0m\n",
       "\u001B[1;32m    508\u001B[0m ArrayList \u001B[38;5;241m=\u001B[39m JavaClass(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjava.util.ArrayList\u001B[39m\u001B[38;5;124m\"\u001B[39m, gateway_client)\n",
       "\u001B[1;32m    509\u001B[0m java_list \u001B[38;5;241m=\u001B[39m ArrayList()\n",
       "\u001B[0;32m--> 510\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m element \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mobject\u001B[39m:\n",
       "\u001B[1;32m    511\u001B[0m     java_list\u001B[38;5;241m.\u001B[39madd(element)\n",
       "\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m java_list\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/column.py:657\u001B[0m, in \u001B[0;36mColumn.__iter__\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    656\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[0;32m--> 657\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumn is not iterable\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: Column is not iterable"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-4204435062209566>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdfnew\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropDuplicates\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdfnew\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_1\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdfnew\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_2\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:3916\u001B[0m, in \u001B[0;36mDataFrame.dropDuplicates\u001B[0;34m(self, subset)\u001B[0m\n\u001B[1;32m   3914\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mdropDuplicates()\n\u001B[1;32m   3915\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 3916\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mdropDuplicates(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jseq\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubset\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   3917\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2624\u001B[0m, in \u001B[0;36mDataFrame._jseq\u001B[0;34m(self, cols, converter)\u001B[0m\n\u001B[1;32m   2618\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_jseq\u001B[39m(\n\u001B[1;32m   2619\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   2620\u001B[0m     cols: Sequence,\n\u001B[1;32m   2621\u001B[0m     converter: Optional[Callable[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrimitiveType\u001B[39m\u001B[38;5;124m\"\u001B[39m, JavaObject]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   2622\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m JavaObject:\n\u001B[1;32m   2623\u001B[0m     \u001B[38;5;124;03m\"\"\"Return a JVM Seq of Columns from a list of Column or names\"\"\"\u001B[39;00m\n\u001B[0;32m-> 2624\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_to_seq\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcols\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconverter\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/column.py:89\u001B[0m, in \u001B[0;36m_to_seq\u001B[0;34m(sc, cols, converter)\u001B[0m\n\u001B[1;32m     87\u001B[0m     cols \u001B[38;5;241m=\u001B[39m [converter(c) \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m cols]\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m sc\u001B[38;5;241m.\u001B[39m_jvm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 89\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jvm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPythonUtils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtoSeq\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1313\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m-> 1313\u001B[0m     args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_args\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1315\u001B[0m     command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m         args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m         proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m     answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1277\u001B[0m, in \u001B[0;36mJavaMember._build_args\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_args\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 1277\u001B[0m         (new_args, temp_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1278\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1279\u001B[0m         new_args \u001B[38;5;241m=\u001B[39m args\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1264\u001B[0m, in \u001B[0;36mJavaMember._get_args\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m   1262\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m converter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39mconverters:\n\u001B[1;32m   1263\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter\u001B[38;5;241m.\u001B[39mcan_convert(arg):\n\u001B[0;32m-> 1264\u001B[0m         temp_arg \u001B[38;5;241m=\u001B[39m \u001B[43mconverter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1265\u001B[0m         temp_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n\u001B[1;32m   1266\u001B[0m         new_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_collections.py:511\u001B[0m, in \u001B[0;36mListConverter.convert\u001B[0;34m(self, object, gateway_client)\u001B[0m\n\u001B[1;32m    509\u001B[0m java_list \u001B[38;5;241m=\u001B[39m ArrayList()\n\u001B[1;32m    510\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m element \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mobject\u001B[39m:\n\u001B[0;32m--> 511\u001B[0m     \u001B[43mjava_list\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43melement\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m java_list\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1313\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m-> 1313\u001B[0m     args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_args\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1315\u001B[0m     command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m         args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m         proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m     answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1277\u001B[0m, in \u001B[0;36mJavaMember._build_args\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_args\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 1277\u001B[0m         (new_args, temp_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1278\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1279\u001B[0m         new_args \u001B[38;5;241m=\u001B[39m args\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1264\u001B[0m, in \u001B[0;36mJavaMember._get_args\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m   1262\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m converter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39mconverters:\n\u001B[1;32m   1263\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter\u001B[38;5;241m.\u001B[39mcan_convert(arg):\n\u001B[0;32m-> 1264\u001B[0m         temp_arg \u001B[38;5;241m=\u001B[39m \u001B[43mconverter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1265\u001B[0m         temp_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n\u001B[1;32m   1266\u001B[0m         new_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_collections.py:510\u001B[0m, in \u001B[0;36mListConverter.convert\u001B[0;34m(self, object, gateway_client)\u001B[0m\n\u001B[1;32m    508\u001B[0m ArrayList \u001B[38;5;241m=\u001B[39m JavaClass(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjava.util.ArrayList\u001B[39m\u001B[38;5;124m\"\u001B[39m, gateway_client)\n\u001B[1;32m    509\u001B[0m java_list \u001B[38;5;241m=\u001B[39m ArrayList()\n\u001B[0;32m--> 510\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m element \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mobject\u001B[39m:\n\u001B[1;32m    511\u001B[0m     java_list\u001B[38;5;241m.\u001B[39madd(element)\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m java_list\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/column.py:657\u001B[0m, in \u001B[0;36mColumn.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    656\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 657\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumn is not iterable\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\n\u001B[0;31mTypeError\u001B[0m: Column is not iterable",
       "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: Column is not iterable",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfnew.dropDuplicates([dfnew._1,dfnew._2]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "949bbd57-cf51-4e55-8783-ae5e15f5a46c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+------+------+\n|eid|    ename| esal|gender|deptno|\n+---+---------+-----+------+------+\n|101|Hariharan|10000|     m|    11|\n|102|    Kalai|20000|     f|    12|\n|104|    Blake|35000|     m|    12|\n+---+---------+-----+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.dropDuplicates([\"deptno\",\"gender\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f94457e4-3ba7-4bed-ae01-a750031511bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[75]: Row(eid=101, ename='Hariharan', esal=10000, gender='m', deptno=11)"
     ]
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cafc843-6cd1-4d97-b119-9dbeba62d799",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rddversion=df.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc964af0-adfb-407b-91e1-3df65cdfb9f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[77]: pyspark.rdd.RDD"
     ]
    }
   ],
   "source": [
    "type(rddversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24c9a951-e32a-49c1-99d4-37bc3d551861",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[78]: [Row(eid=101, ename='Hariharan', esal=10000, gender='m', deptno=11),\n Row(eid=102, ename='Kalai', esal=20000, gender='f', deptno=12),\n Row(eid=103, ename='Sivam', esal=30000, gender='m', deptno=11),\n Row(eid=104, ename='Blake', esal=35000, gender='m', deptno=12),\n Row(eid=105, ename='James', esal=40000, gender='m', deptno=11)]"
     ]
    }
   ],
   "source": [
    "rddversion.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c83aa1f-1331-4854-8849-90e733e69c9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+------+------+\n|eid|    ename| esal|gender|deptno|\n+---+---------+-----+------+------+\n|101|Hariharan|10000|  male|    11|\n|102|    Kalai|20000|female|    12|\n|103|    Sivam|30000|  male|    11|\n|104|    Blake|35000|  male|    12|\n|105|    James|40000|  male|    11|\n+---+---------+-----+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "#replace\n",
    "df10=df.replace(['m','f'],['male','female'],'gender')\n",
    "df10.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3eaf9d5c-359b-4925-af08-e93f9b11b60e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "`if i want to change the column name or schema\n",
    "eid-> empID\n",
    "esal->income\n",
    "deptno->no`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7c1bfb6-21ba-4c64-9ed2-c1aac10bdfa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+------+------+---+\n|empid|    ename|income|gender|dno|\n+-----+---------+------+------+---+\n|  101|Hariharan| 10000|     m| 11|\n|  102|    Kalai| 20000|     f| 12|\n|  103|    Sivam| 30000|     m| 11|\n|  104|    Blake| 35000|     m| 12|\n|  105|    James| 40000|     m| 11|\n+-----+---------+------+------+---+\n\n"
     ]
    }
   ],
   "source": [
    "dfnewschema=df.toDF('empid','ename','income','gender','dno')\n",
    "dfnewschema.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20b3b023-de3b-416c-b072-40e5b16b38b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "withColumnRenamed-> renaming a particular column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93cef458-b8b8-4ede-8c48-dd3a06a8b2ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-----+------+------+\n|eid|employeename| esal|gender|deptno|\n+---+------------+-----+------+------+\n|101|   Hariharan|10000|     m|    11|\n|102|       Kalai|20000|     f|    12|\n|103|       Sivam|30000|     m|    11|\n|104|       Blake|35000|     m|    12|\n|105|       James|40000|     m|    11|\n+---+------------+-----+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"ename\",\"employeename\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13a1d3ab-8faf-44a5-be27-0f47c1649f9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "withColumn will create additional column to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed3fdb51-7a3b-4fdb-b9a1-b21ba6c938b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+------+------+-------+\n|eid|    ename| esal|gender|deptno|  bonus|\n+---+---------+-----+------+------+-------+\n|101|Hariharan|10000|     m|    11|11000.0|\n|102|    Kalai|20000|     f|    12|22000.0|\n|103|    Sivam|30000|     m|    11|33000.0|\n|104|    Blake|35000|     m|    12|38500.0|\n|105|    James|40000|     m|    11|44000.0|\n+---+---------+-----+------+------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"bonus\",df.esal+df.esal*0.1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb1ec3b2-1d03-4e50-8f42-ced46b94871d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "we can convert a dataframe to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33bab1f7-7477-4ffe-9d19-3cda2e3e015b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[88]: ['{\"eid\":101,\"ename\":\"Hariharan\",\"esal\":10000,\"gender\":\"m\",\"deptno\":11}',\n '{\"eid\":102,\"ename\":\"Kalai\",\"esal\":20000,\"gender\":\"f\",\"deptno\":12}',\n '{\"eid\":103,\"ename\":\"Sivam\",\"esal\":30000,\"gender\":\"m\",\"deptno\":11}',\n '{\"eid\":104,\"ename\":\"Blake\",\"esal\":35000,\"gender\":\"m\",\"deptno\":12}',\n '{\"eid\":105,\"ename\":\"James\",\"esal\":40000,\"gender\":\"m\",\"deptno\":11}']"
     ]
    }
   ],
   "source": [
    "df.toJSON().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8b8f982-e80f-4088-acec-2331493f5f40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "groupBy used to group as per the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6a5f773-f824-48b0-925a-f2abd43d2dd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+------+------+\n|eid|    ename| esal|gender|deptno|\n+---+---------+-----+------+------+\n|101|Hariharan|10000|     m|    11|\n|102|    Kalai|20000|     f|    12|\n|103|    Sivam|30000|     m|    11|\n|104|    Blake|35000|     m|    12|\n|105|    James|40000|     m|    11|\n+---+---------+-----+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b182aaed-2adf-4252-9512-c9471c0f5bd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n|deptno|count|\n+------+-----+\n|    12|    2|\n|    11|    3|\n+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "result=df.groupBy(\"deptno\").count()\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9811103d-62f6-4360-9bab-cd63caba205d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Aggregated Functions\n",
    "\n",
    "agg()\n",
    "sum()\n",
    "min()\n",
    "max()\n",
    "avg()\n",
    "count()\n",
    "\n",
    "we have to impor the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27705f37-22c2-409c-8bcd-6879ba47fc39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97ae435b-d1ad-4ba1-93e6-2a1449fb0403",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n|deptno|number of employees|\n+------+-------------------+\n|    12|                  2|\n|    11|                  3|\n+------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"deptno\").agg(count('gender').alias(\"number of employees\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "535c96e5-44a2-4572-9bd3-e7c793c29396",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n|deptno|sum(esal)|\n+------+---------+\n|    12|    55000|\n|    11|    80000|\n+------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"deptno\").sum(\"esal\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6374fe90-db0b-422f-8678-0d00fc2d5f0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---------+\n|deptno|gender|sum(esal)|\n+------+------+---------+\n|    12|     f|    20000|\n|    11|     m|    80000|\n|    12|     m|    35000|\n+------+------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"deptno\",\"gender\").sum(\"esal\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d297397-96ac-42c0-af5f-462d722eba1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---------+\n|deptno|gender|sum(esal)|\n+------+------+---------+\n|    12|     f|    20000|\n|    11|     m|    80000|\n|    12|     m|    35000|\n+------+------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"deptno\",\"gender\").sum(\"esal\").orderBy(\"gender\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec5cf9e1-cf5f-4a9c-bdd3-f9de6b7b5de5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DataFrame_using_pyspark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}